# ClipSwap: Towards High Fidelity Face Swapping via Attributes and CLIP-Informed Loss (FG 2024 Oral)

Phyo Thet Yee, Sudeepta Mishra, Abhinav Dhall
<br><br>

#We present ClipSwap, a new framework designed for high-fidelity face swapping. We use a conditional Generative Adversarial Network and a CLIP-based encoder, which extracts rich semantic knowledge to achieve attributes-aware face swapping. Our framework uses CLIP embedding in the face swapping process for improving the transmission of source imageâ€™s identity details to the swapped image by refining the high-level semantic attributes obtained from the source image. And source image serves as the input reference image for CLIP and ensures a more accurate and detailed identity representation in the final result. Additionally, we apply Contrastive Loss to guide the transformation of source facial attributes onto the swapped image from various viewpoints. We also introduce Attributes Preservation Loss, which penalizes the network to keep the facial attributes of the target image.

<br><br>
![clipswap](https://github.com/novicemm/ClipSwap-Towards-High-Fidelity-Face-Swapping-via-Attributes-and-CLIP-Informed-Loss-FG-2024-Oral-/assets/42999480/d034e8cb-6ad3-4f09-92cf-c3d4127cc610)

<br><br>
**Model Architecture**

![framework](https://github.com/novicemm/ClipSwap-Towards-High-Fidelity-Face-Swapping-via-Attributes-and-CLIP-Informed-Loss-FG-2024-Oral-/assets/42999480/ab994791-5df1-4b68-a30d-050cdff3d6e3)

<br><br>
**Results**

![results](https://github.com/novicemm/ClipSwap-Towards-High-Fidelity-Face-Swapping-via-Attributes-and-CLIP-Informed-Loss-FG-2024-Oral-/assets/42999480/c237a03c-8ab6-4d08-a1ae-63c51ef2ccf4)

<br><br>
**Wild Image Results**

![wild_images](https://github.com/novicemm/ClipSwap-Towards-High-Fidelity-Face-Swapping-via-Attributes-and-CLIP-Informed-Loss-FG-2024-Oral-/assets/42999480/96859be5-bacb-478a-bf00-f84a21e65629)

<br><br>
**Code (Coming Soon)**
